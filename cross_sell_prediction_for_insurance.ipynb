{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, auc, RocCurveDisplay\n",
    "from imblearn.over_sampling import SMOTENC, RandomOverSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "BASE_URL = os.getcwd()\n",
    "\n",
    "# Constructing file paths using os.path.join\n",
    "train_file_path = os.path.join(BASE_URL, 'train.csv')\n",
    "test_file_path = os.path.join(BASE_URL, 'test.csv')\n",
    "\n",
    "# Reading CSV files\n",
    "df_train = pd.read_csv(train_file_path)\n",
    "df_test = pd.read_csv(test_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BASE_URL = 'C:/Users/stede/OneDrive/locdocs/professionAI/fondamenti di machine learning/progetto finale/'\n",
    "df_train = pd.read_csv(BASE_URL + 'train.csv')\n",
    "df_test = pd.read_csv(BASE_URL + 'test.csv')\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning datasets from possible typing errors, and dropping the 'id' columns\n",
    "\n",
    "df_train.columns = df_train.columns.str.strip().str.replace(' ', '_')\n",
    "df_test.columns = df_test.columns.str.strip().str.replace(' ', '_')\n",
    "\n",
    "df_train = df_train.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking any possible null value\n",
    "\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the target variable 'Response'\n",
    "\n",
    "\"\"\"\n",
    "From the graph we can see that the target variable 'Response' is strongly unbalanced.\n",
    "\"\"\"\n",
    "\n",
    "sns.countplot(x='Response', data=df_train)\n",
    "plt.title('Distribution of Response')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 'Age'\n",
    "\n",
    "sns.countplot(x='Age', data=df_train)\n",
    "plt.title('Age Distribution')\n",
    "plt.xticks(range(0, df_train['Age'].max()+1, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing categorical variables ('cat_var') and numerical variables ('num_var')\n",
    "\n",
    "cat_var = ['Gender', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Policy_Sales_Channel']\n",
    "num_var = ['Age', 'Vintage', 'Annual_Premium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions of the categorical features\n",
    "\n",
    "for var in cat_var:\n",
    "    sns.countplot(x = var, data = df_train)\n",
    "    plt.title(f'Distribution of {var}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between quantitative features and the target variable\n",
    "\n",
    "\"\"\"\n",
    "We can notice that the Age can be a factor on the forecasted response of \n",
    "the customer, as the older ones tend to respond more positively to the offer.\n",
    "\"\"\"\n",
    "\n",
    "for var in num_var:\n",
    "    sns.boxplot(x = 'Response', y = var, data = df_train)\n",
    "    plt.title(f'{var} vs. Response')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical features with the LabelEncoder\n",
    "\n",
    "LabEnc = LabelEncoder()\n",
    "df_train['Gender'] = LabEnc.fit_transform(df_train['Gender'])\n",
    "df_test['Gender'] = LabEnc.transform(df_test['Gender'])\n",
    "\n",
    "LabEnc = LabelEncoder()\n",
    "df_train['Vehicle_Damage'] = LabEnc.fit_transform(df_train['Vehicle_Damage'])\n",
    "df_test['Vehicle_Damage'] = LabEnc.transform(df_test['Vehicle_Damage'])\n",
    "\n",
    "df_train[\"Region_Code\"] = df_train[\"Region_Code\"].astype(\"str\")\n",
    "df_test[\"Region_Code\"] = df_test[\"Region_Code\"].astype(\"str\")\n",
    "LabEnc = LabelEncoder()\n",
    "df_train['Region_Code'] = LabEnc.fit_transform(df_train['Region_Code'])\n",
    "df_test['Region_Code'] = LabEnc.transform(df_test['Region_Code'])\n",
    "\n",
    "Vehicle_Age = {'< 1 Year':0, '1-2 Year':1, '> 2 Years':2}\n",
    "df_train['Vehicle_Age'] = df_train['Vehicle_Age'].map(Vehicle_Age)\n",
    "df_test['Vehicle_Age'] = df_test['Vehicle_Age'].map(Vehicle_Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StdScl = StandardScaler()\n",
    "\n",
    "df_train[num_var] = StdScl.fit_transform(df_train[num_var])\n",
    "df_test[num_var] = StdScl.transform(df_test[num_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The features that are most correlated with the target variable seem to be \n",
    "'Vehicle_Damage' (positively correlated) and 'Previously_Insured' \n",
    "(negatively correlated). This makes sense, as customers who have had an \n",
    "incident in the past will be more likely to take out an insurance policy. \n",
    "Those who already have an insured vehicle, are more unlikely to have an \n",
    "additional vehicle to insure.\n",
    "\"\"\"\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_train.corr(), annot = True, annot_kws = {'size': 9}, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the feature encoding had effect on the dataset\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a constant 'RS' (RANDOM_SEED) for the 'random_state' attirbute\n",
    "RS = 25\n",
    "\n",
    "# Splitting the variables into features and target\n",
    "X = df_train.drop(['Response'], axis=1)\n",
    "y = df_train['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We use the 'stratify' parameter to ensure that the distribution of the target variable 'Response' \n",
    "is preserved in both the training and testing sets. \n",
    "By setting the 'shuffle' parameter as True, we want to avoid any possible ordering in the dataset,\n",
    "like taking all the observations for our test set from one specific Region Code.\n",
    "\"\"\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RS, stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "By performing oversampling with the SMOTE_NC method (an extension of the SMOTE algorithm) \n",
    "we are able to effectively handles datasets with both quantitative and categorical features.\n",
    "https://imbalanced-learn.org/stable/over_sampling.html\n",
    "\"\"\"\n",
    "\n",
    "cat_var_mask = X.columns.isin(cat_var)\n",
    "\n",
    "smotenc = SMOTENC(categorical_features=cat_var_mask, random_state=RS)\n",
    "X, y = smotenc.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RanFor = RandomForestClassifier(n_estimators=62, max_depth=17, random_state=RS, class_weight='balanced')\n",
    "\n",
    "RanFor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = RanFor.predict(X_train)\n",
    "y_proba_train = RanFor.predict_proba(X_train)\n",
    "y_pred_test = RanFor.predict(X_test)\n",
    "y_proba_test = RanFor.predict_proba(X_test)\n",
    "\n",
    "print(\"TRAIN REPORT - RandomForestClassifier\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"TEST REPORT - RandomForestClassifier\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_train = RanFor.predict_proba(X_train)[:, 1]\n",
    "y_proba_test = RanFor.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(roc_auc_score(y_train, y_proba_train))\n",
    "print(roc_auc_score(y_test, y_proba_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's comment the result obtained with the RandomForestClassifier:\n",
    "\n",
    "For class 0, we have high precision but low recall. This means that when \n",
    "the model predicts a customer is in class 0 (not interested), it is often \n",
    "correct, but it misses a large portion of the total actual 0s, so it \n",
    "wrongly classifies many actual 0s (not interested) as 1s (interested).\n",
    "\n",
    "For class 1, we have lower precision but higher recall. This means the model \n",
    "identifies a high proportion of actual 1s (interested) correctly, but in \n",
    "doing so, it also wrongly identifies many 0s (not interested) as 1s \n",
    "(interested), leading to a high number of false positives.\"\n",
    "\n",
    "The ROC-AUC score of 92.21% on the test is actually not a bad result.\n",
    "Being this model more liberal on class 1, it could be useful for \n",
    "initial broad-based marketing efforts.\n",
    "\n",
    "Let's see if we can find a more precise model though...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatBst = CatBoostClassifier(verbose=100)\n",
    "\n",
    "CatBst.fit(X_train, y_train, eval_set = (X_test, y_test), early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = CatBst.predict(X_train)\n",
    "y_proba_train = CatBst.predict_proba(X_train)\n",
    "y_pred_test = CatBst.predict(X_test)\n",
    "y_proba_test = CatBst.predict_proba(X_test)\n",
    "\n",
    "print(\"TRAIN REPORT - CatBoostClassifier\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"TEST REPORT - CatBoostClassifier\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_train = CatBst.predict_proba(X_train)[:, 1]\n",
    "y_proba_test = CatBst.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(roc_auc_score(y_train, y_proba_train))\n",
    "print(roc_auc_score(y_test, y_proba_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The CatBoostClassifier gave a ROC-AUC score of 96.27% on the test set.\n",
    "It suggests that the model can accurately identify positive instances \n",
    "while keeping the number of false positives low.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "XGBC = XGBClassifier(random_state=RS)\n",
    "XGBC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "y_pred_train = XGBC.predict(X_train)\n",
    "y_proba_train = XGBC.predict_proba(X_train)\n",
    "y_pred_test = XGBC.predict(X_test)\n",
    "y_proba_test = XGBC.predict_proba(X_test)\n",
    "\n",
    "print(\"TRAIN REPORT - XGBClassifier\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"TEST REPORT - XGBClassifier\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "y_proba_train = XGBC.predict_proba(X_train)[:, 1]\n",
    "y_proba_test = XGBC.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(roc_auc_score(y_train, y_proba_train))\n",
    "print(roc_auc_score(y_test, y_proba_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "With a ROC-AUC of 96.51% on the test set, the XGBClassifier represents\n",
    "an improvement on the CatBoostClassifier, and it also proved to be\n",
    "less computationally expensive.\n",
    "We are going to use this model for our predictions on the test set:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Applying the model to the test data\n",
    "df_test_id = df_test['id']\n",
    "df_test = df_test.drop(['id'], axis=1)\n",
    "df_test_pred = XGBC.predict(df_test)\n",
    "df_test_pred_proba = XGBC.predict_proba(df_test)\n",
    "\n",
    "# Creating a new dataframe for the predictions\n",
    "df_predictions = pd.DataFrame({\n",
    "    'id': df_test_id,\n",
    "    'Response': df_test_pred,\n",
    "    'Probability_0': df_test_pred_proba[:, 0],\n",
    "    'Probability_1': df_test_pred_proba[:, 1]\n",
    "})\n",
    "\n",
    "df_predictions.to_excel(BASE_URL + 'vehicle_insurance_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GrdBst = GradientBoostingClassifier(random_state=RS)\n",
    "\n",
    "GrdBst.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = GrdBst.predict(X_train)\n",
    "y_proba_train = GrdBst.predict_proba(X_train)\n",
    "y_pred_test = GrdBst.predict(X_test)\n",
    "y_proba_test = GrdBst.predict_proba(X_test)\n",
    "\n",
    "print(\"TRAIN REPORT - GradientBoostingClassifier\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"TEST REPORT - GradientBoostingClassifier\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_train = GrdBst.predict_proba(X_train)[:, 1]\n",
    "y_proba_test = GrdBst.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(roc_auc_score(y_train, y_proba_train))\n",
    "print(roc_auc_score(y_test, y_proba_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The GradientBoostingClassifier shows many false positive, even more than\n",
    "the RandomForestClassifier, and it actually doesn't represent an \n",
    "improvement over any of the model we saw above.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
