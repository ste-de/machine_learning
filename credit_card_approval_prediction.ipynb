{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, classification_report, confusion_matrix, roc_auc_score, accuracy_score, log_loss\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0\n",
    "# Define BASE_URL for local computing\n",
    "BASE_URL = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "application_record_file_path = os.path.join(BASE_URL, 'credit_card_approval/application_record.csv')\n",
    "credit_record_file_path = os.path.join(BASE_URL, 'credit_card_approval/credit_record.csv')\n",
    "\n",
    "application_record = pd.read_csv(application_record_file_path)\n",
    "credit_record = pd.read_csv(credit_record_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### application_record dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Seems like occupation_type has many null values.\n",
    "\"\"\"\n",
    "application_record.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In 'OCCUPATION_TYPE', replace NaN entries with 'Other'\n",
    "application_record['OCCUPATION_TYPE'].fillna('Other', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Total number of rows is 438,557, while unique IDs are 438,510.\n",
    "That means the dataset has 47 duplicates.\n",
    "\"\"\"\n",
    "application_record['ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the entries by the 'ID' column, to have a better view on the duplicates\n",
    "application_record = application_record.sort_values(by='ID')\n",
    "duplicates = application_record[application_record.duplicated(subset='ID', keep=False)]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "It seems like the duplicates don't refer to the same customer.\n",
    "We can also exclude the hypothesis that we are dealing with joint accounts,\n",
    "since data related to 'CNT_CHILDREN' and 'NAME_FAMILY_STATUS' don't coincide.\n",
    "With these premises, possibly the best thing to do is to delete all the\n",
    "duplicates, without keeping any of them.\n",
    "\"\"\"\n",
    "application_record = application_record.drop_duplicates(subset='ID', keep=False)\n",
    "application_record['ID'].nunique() # now we have 438,510 - 47 = 438,463 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the column names more readable\n",
    "new_column_names = {\n",
    "    'CODE_GENDER': 'GENDER',\n",
    "    'AMT_INCOME_TOTAL': 'INCOME_TOTAL',\n",
    "    'FLAG_OWN_CAR': 'OWN_CAR',\n",
    "    'FLAG_OWN_REALTY': 'OWN_REALTY',\n",
    "    'NAME_INCOME_TYPE': 'INCOME_TYPE',\n",
    "    'NAME_EDUCATION_TYPE': 'EDUCATION_TYPE',\n",
    "    'NAME_FAMILY_STATUS': 'FAMILY_STATUS',\n",
    "    'NAME_HOUSING_TYPE': 'HOUSING_TYPE',\n",
    "    'CNT_FAM_MEMBERS': 'FAM_MEMBERS'\n",
    "}\n",
    "\n",
    "application_record.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "It turned out that all the entries with 'INCOME_TYPE' = 'Pensioner' also show\n",
    "'DAYS_EMPLOYED' = 365243. As this is the only positive value in the column, we\n",
    "can conclude that all the other customers are currently working. That means\n",
    "all the customers here have a monthly income.\n",
    "\"\"\"\n",
    "# Create 'AGE' feature\n",
    "application_record['AGE'] = (- application_record['DAYS_BIRTH'] / 365.25).astype(int)\n",
    "application_record.drop('DAYS_BIRTH', axis=1, inplace=True)\n",
    "\n",
    "# Create 'YEARS_EMPLOYED' feature and drop 'DAYS_EMPLOYED'\n",
    "application_record['YEARS_EMPLOYED'] = (- application_record['DAYS_EMPLOYED'] / 365.25).astype(int)\n",
    "application_record.loc[application_record['YEARS_EMPLOYED'] < 0,'YEARS_EMPLOYED'] = 0\n",
    "application_record.drop('DAYS_EMPLOYED', axis=1, inplace=True)\n",
    "application_record.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Label Encoding Categorical Columns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_label(dataframe, column):\n",
    "    if column in dataframe.columns:\n",
    "        label_encoder = LabelEncoder()\n",
    "        dataframe[column] = label_encoder.fit_transform(dataframe[column])\n",
    "    else:\n",
    "        print(f\"Column '{column}' not found in the DataFrame.\")\n",
    "\n",
    "\n",
    "categorical_columns = ['GENDER', 'OWN_CAR', 'OWN_REALTY', 'INCOME_TYPE', 'EDUCATION_TYPE', 'FAMILY_STATUS', 'HOUSING_TYPE', 'OCCUPATION_TYPE']\n",
    "\n",
    "# Apply LabelEncoder to each categorical column\n",
    "for column in categorical_columns:\n",
    "    encode_label(application_record, column)\n",
    "\n",
    "application_record.head()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map categorical values \n",
    "def replace_values(dataframe, column, value_mapping):\n",
    "    dataframe[column].replace(value_mapping, inplace=True)\n",
    "\n",
    "gender_mapping = {'M':0, 'F':1}\n",
    "car_mapping = {'N':0, 'Y':1}\n",
    "realty_mapping = {'N':0, 'Y':1}\n",
    "\n",
    "income_type_mapping = {\n",
    "    'Student': 1, 'Commercial associate': 2,\n",
    "    'Working': 3, 'Pensioner': 4, 'State servant': 5,\n",
    "}\n",
    "education_type_mapping = {\n",
    "    'Lower secondary': 1, 'Incomplete higher': 2,\n",
    "    'Secondary / secondary special': 3,\n",
    "    'Higher education': 3, 'Academic degree': 4\n",
    "}\n",
    "family_status_mapping = {\n",
    "    'Separated': 1, 'Married': 2, 'Civil marriage': 3,\n",
    "    'Single / not married': 3, 'Widow': 4\n",
    "}\n",
    "housing_type_mapping = {\n",
    "    'Rented apartment': 1, 'Co-op apartment': 2,\n",
    "    'Municipal apartment': 3, 'With parents': 4,\n",
    "    'Office apartment': 5, 'House / apartment': 6\n",
    "}\n",
    "occupation_type_mapping = {\n",
    "    'Low-skill Laborers': 1, 'Waiters/barmen staff': 2,\n",
    "    'Sales staff': 3, 'Low-skill Laborers': 4, 'Cleaning staff': 5,\n",
    "    'Private service staff': 6, 'Cooking staff': 7, 'Security staff': 8,\n",
    "    'Drivers': 9, 'HR staff': 10, 'Secretaries': 11, 'Core staff': 12,\n",
    "    'Laborers': 13, 'Medicine staff': 14, 'Realty agents': 15,\n",
    "    'Managers': 16, 'High skill tech staff': 17, 'IT staff': 18,\n",
    "    'Accountants': 19, 'Other': 20,\n",
    "}\n",
    "status_mapping = {'C':0, 'X':0.5, '0':1, '1':2, '2':4, '3':8, '4':16, '5':32}\n",
    "\n",
    "\"\"\"\n",
    "'C': 0 - Paid off that month\n",
    "'X': 0.5 - No loan for the month\n",
    "'0': 1 - 1-29 days past due\n",
    "'1': 2 - 30-59 days past due\n",
    "'2': 4 - 60-89 days past overdue\n",
    "'3': 8 - 90-119 days past overdue\n",
    "'4': 16 - 120-149 days past overdue\n",
    "'5': 32 - Overdue or bad debts, write-offs for more than 150 days\n",
    "\n",
    "NOTE on 'STATUS' coefficients: the scores that will be created starting from\n",
    "this weights will be normalized ahead during this work. As for now, I decided\n",
    "to assign arbitrary coefficients to any status, that increase quadratically\n",
    "as the customer doesn't repay his debt within a given time window.\n",
    "\n",
    "NOTE on 'X': I decided to assign a coefficient of 0.5 to the status 'X'.\n",
    "In fact, banks usually prefer clients that actually borrow money through the\n",
    "credit card they've been given. Furthermore, if a client has no credit history\n",
    "at all, banks will consider the release of a credit card more carefully.\n",
    "For example, customer 'ID' 5001731 has a record made of 11 entries, in which the\n",
    "'STATUS' is always 'X'. With the system here developed, the 'ID_SCORE' will be\n",
    "(11 * 0.5) / (11) = 0.5. This won't affect the card release if all the other\n",
    "parameters are good, but the client will be slightly penalized with respect to\n",
    "one that already has a good credit history.\n",
    "\n",
    "NOTE on INCOME_TYPE: I tried to encode the income types from the least stable\n",
    "to the most reliable.\n",
    "\n",
    "NOTE on EDUCATION_TYPE: I encoded the grades from the lowest to the highest,\n",
    "assigning '3' to both 'Secondary / secondary special' and 'Higher education',\n",
    "as they seem to refer to the same grade.\n",
    "\"\"\"\n",
    "\n",
    "replace_values(application_record, 'GENDER', gender_mapping)\n",
    "replace_values(application_record, 'OWN_CAR', car_mapping)\n",
    "replace_values(application_record, 'OWN_REALTY', realty_mapping)\n",
    "replace_values(application_record, 'INCOME_TYPE', income_type_mapping)\n",
    "replace_values(application_record, 'EDUCATION_TYPE', education_type_mapping)\n",
    "replace_values(application_record, 'FAMILY_STATUS', family_status_mapping)\n",
    "replace_values(application_record, 'HOUSING_TYPE', housing_type_mapping)\n",
    "replace_values(application_record, 'OCCUPATION_TYPE', occupation_type_mapping)\n",
    "replace_values(credit_record, 'STATUS', status_mapping)\n",
    "\n",
    "application_record.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type into 'int'\n",
    "application_record = application_record.astype(int)\n",
    "application_record.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### credit_record dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_record.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This dataset has 45,985 unique rows, against 1,048,575 total entries.\n",
    "That happens because the column 'MONTHS_BALANCE' has one entry per any single\n",
    "month, starting from the month in which the credit card has been released to\n",
    "the customer.\n",
    "\"\"\"\n",
    "credit_record['ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the account age, expressed in months, by getting the lowest entry\n",
    "# from the 'MONTHS_BALANCE' column for any 'ID', then adding 1 (current month)\n",
    "month_balance_sum = pd.DataFrame(credit_record.groupby(['ID'])['MONTHS_BALANCE']\n",
    "                                 .agg(min)).reset_index()\n",
    "# Rename the column to 'ACCOUNT_AGE'\n",
    "month_balance_sum.rename(columns={'MONTHS_BALANCE':'ACCOUNT_AGE'}, inplace=True)\n",
    "# Turn the entries into positive\n",
    "month_balance_sum['ACCOUNT_AGE']= - month_balance_sum['ACCOUNT_AGE'] + 1\n",
    "# Merge dataframes according to the 'ID' column\n",
    "credit_record = pd.merge(month_balance_sum, credit_record, how='inner', on=['ID'])\n",
    "# Drop 'MONTHS_BALANCE'\n",
    "credit_record.drop(columns=['MONTHS_BALANCE'], inplace=True)\n",
    "\n",
    "credit_record.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix of 'credit_record'\n",
    "correlation_matrix = credit_record.corr()\n",
    "\n",
    "\"\"\"\n",
    "There are no particular correlations between the 'ACCOUNT_AGE' and the debt 'STATUS'\n",
    "\"\"\"\n",
    "\n",
    "# Create a heatmap for visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the 'STATUS' coefficient for any 'ID'\n",
    "status_sum = pd.DataFrame(credit_record.groupby(['ID'])['STATUS']\n",
    "                                 .sum()).reset_index()\n",
    "# Rename 'STATUS' into 'STATUS_SUM'\n",
    "status_sum.rename(columns={'STATUS':'STATUS_SUM'}, inplace=True)\n",
    "# Merge dataframes according to the 'ID' column\n",
    "credit_record = pd.merge(status_sum, credit_record, how='inner', on=['ID'])\n",
    "# Drop 'STATUS'\n",
    "credit_record.drop(columns=['STATUS'], inplace=True)\n",
    "\n",
    "credit_record.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate the duplicates in 'credit_record'\n",
    "credit_record.drop_duplicates(inplace=True)\n",
    "\n",
    "# Create column 'CREDIT_SCORE', which is equal to 'STATUS_SUM' divided by\n",
    "# 'ACCOUNT_AGE'. The lower the score, the better\n",
    "credit_record['CREDIT_SCORE'] = credit_record['STATUS_SUM'] / credit_record['ACCOUNT_AGE']\n",
    "credit_record['CREDIT_SCORE'] = credit_record['CREDIT_SCORE'].round(2)\n",
    "\n",
    "credit_record.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_record.drop('STATUS_SUM', axis=1, inplace=True)\n",
    "\n",
    "sorted_credit_record = credit_record.sort_values(by='CREDIT_SCORE', ascending=False)\n",
    "sorted_credit_record.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE: A first threshold has been set, corrensponding to 'CREDIT_SCORE' = '1'.\n",
    "In particular, if a customer has 'CREDIT_SCORE' >= 1 (originally corresponding to\n",
    "'STATUS' = '0': 1-29 days past overdue) he's going to be considered a bad customer.\n",
    "Here are some examples of 'CREDIT_SCORE' and its corrensponding normalized value:\n",
    "1 = 0.034674\n",
    "2 = 0.069348\n",
    "3 = 0.104022\n",
    "4 = 0.138696\n",
    "If the coefficient is < 1, card will be released.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'IS_GOOD' column\n",
    "credit_record['IS_GOOD'] = np.where(credit_record['CREDIT_SCORE'] < 1, 1, 0)\n",
    "credit_record = credit_record.drop(columns='CREDIT_SCORE')\n",
    "credit_record.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join on the 'ID' column\n",
    "data = pd.merge(application_record, credit_record, on='ID', how='inner')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many records match in two datasets\n",
    "len(set(credit_record['ID']).intersection(set(application_record['ID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We have 36457 unique ID values, which correspond to the number of records that match\n",
    "between the two datasets.\n",
    "\"\"\"\n",
    "data['ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['IS_GOOD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Percentage of 'IS_GOOD' = 0: (4862 / 36457) * 100 ≈ 13.34%\n",
    "The dataset is highly unbalanced.\n",
    "\"\"\"\n",
    "(4862 / 36457) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the correlation matrix\n",
    "\n",
    "# Check if 'ID' column exists in the DataFrame\n",
    "if 'ID' in data.columns:\n",
    "    # Create a copy of the DataFrame without the 'ID' column\n",
    "    data_corr = data.drop(columns=['ID'])\n",
    "else:\n",
    "    # If 'ID' column is not found, use the entire DataFrame\n",
    "    data_corr = data\n",
    "\n",
    "correlation_matrix = data_corr.corr()\n",
    "\n",
    "# Create a heatmap for visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"'data' Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "'FLAG_MOBIL' has been excluded from the correlation matrix, as the only possible \n",
    "value it shows it's 1. For this reson the column is going to be dropped.\n",
    "\"\"\"\n",
    "data['FLAG_MOBIL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that are not useful for the model\n",
    "\"\"\"\n",
    ", 'ACCOUNT_AGE'\n",
    "\"\"\"\n",
    "data.drop(columns=['GENDER', 'CNT_CHILDREN', 'FAMILY_STATUS', 'HOUSING_TYPE', \n",
    "                    'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', \n",
    "                    'OCCUPATION_TYPE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a csv document for 'data'\n",
    "data.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the target variable\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='IS_GOOD', data=data, palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left anti join to get entries in 'application_record' that are not\n",
    "# in 'credit_record'. On this dataset we will make our predicitons\n",
    "df_pred = application_record.merge(credit_record, on='ID', how='left', indicator=True).query('_merge == \"left_only\"')\n",
    "# Drop the '_merge' column which was added by the query operation\n",
    "df_pred = df_pred.drop(['_merge', 'GENDER', 'CNT_CHILDREN', 'FAMILY_STATUS', 'HOUSING_TYPE', 'FLAG_MOBIL', \n",
    "                                 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', 'ACCOUNT_AGE', 'OCCUPATION_TYPE',   \n",
    "                                'IS_GOOD'], axis=1)\n",
    "\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a csv document for 'df_pred'\n",
    "df_pred.to_csv('df_pred.csv', index=False)\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "\"\"\"\n",
    "Use of the 'stratify' parameter to ensure that the distribution of the target variable\n",
    "'Response' is preserved in both the training and testing sets.\n",
    "Set the 'shuffle' parameter to True, to avoid any possible ordering in the dataset.\n",
    "\"\"\"\n",
    "\n",
    "x = data.drop(columns=['ID', 'IS_GOOD']).values\n",
    "y = data['IS_GOOD'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3,\n",
    "                                                    random_state=RANDOM_SEED, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given our primary objective, i.e., to understand why a customer's credit card\n",
    "request has not been accepted, I'll perfomr the SMOTE algorithm.\n",
    "The SMOTE (Synthetic Minority Oversampling Technique) operates by generating\n",
    "synthetic minority class observations through interpolation between existing\n",
    "minority class samples. This oversampling technique will help us\n",
    "create a more balanced dataset, allowing our machine learning model to learn from\n",
    "a more representative set of examples.\n",
    "\"\"\"\n",
    "\n",
    "smote = SMOTE(random_state=RANDOM_SEED, k_neighbors=3)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "# Checking the new class counts\n",
    "print('New class 0:', sum(y_train == 0))\n",
    "print('New class 1:', sum(y_train == 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The model I chose to predict my rsults is the RandomForestClassifier. \n",
    "The confusion matrix shows this is the model that reduces false positives the most.\n",
    "It must be preferred, indeed, a model that minimizes the risk of releasing the\n",
    "credit card to a customer who is not actually a good one.\n",
    "\n",
    "Regarding the reasons of the denial, the feature 'YEARS_EMPLOYED' is definitely\n",
    "the most influent on the decision, showing that a stable job position matches \n",
    "a higher chance to repay expenditures.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_features='sqrt'\n",
    "RanFor = RandomForestClassifier(n_estimators=256, max_features='sqrt', max_depth=12, random_state=RANDOM_SEED, \n",
    "                                min_samples_split=4, min_samples_leaf=16, class_weight={0:1, 1:0.5}, n_jobs=-1,\n",
    "                                criterion='entropy')\n",
    "RanFor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = RanFor.predict(x_train)\n",
    "y_proba_train = RanFor.predict_proba(x_train)\n",
    "y_pred_test = RanFor.predict(x_test)\n",
    "y_proba_test = RanFor.predict_proba(x_test)\n",
    "\n",
    "print(\"TRAIN REPORT - RandomForestClassifier\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"TEST REPORT - RandomForestClassifier\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the feature importances\n",
    "feature_importances = RanFor.feature_importances_\n",
    "\n",
    "# Match feature importances with feature names (assuming you have feature names)\n",
    "feature_names = ['ID', 'OWN_CAR', 'OWN_REALTY', 'INCOME_TOTAL',\n",
    "       'EDUCATION_TYPE', 'OCCUPATION_TYPE', 'FAM_MEMBERS', 'AGE', 'YEARS_EMPLOYED', \n",
    "       'ACCOUNT_AGE', 'IS_GOOD']\n",
    "\n",
    "# Create a list of tuples (feature name, importance)\n",
    "feature_importance_tuples = [(feature, importance) for feature, importance in zip(feature_names, feature_importances)]\n",
    "\n",
    "# Sort the list by importance (from highest to lowest)\n",
    "feature_importance_tuples.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted feature importances\n",
    "for feature, importance in feature_importance_tuples:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# For training data\n",
    "cm_train = confusion_matrix(y_train, y_pred_train)\n",
    "print(\"Confusion Matrix (Train):\\n\", cm_train)\n",
    "\n",
    "# For test data\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Confusion Matrix (Test):\\n\", cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate ROC curve and AUC for test data\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba_test[:, 1])\n",
    "auc = roc_auc_score(y_test, y_proba_test[:, 1])\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the model to the test data\n",
    "df_pred_id = df_pred['ID']\n",
    "# df_pred = df_pred.drop(['ID'], axis=1)\n",
    "df_pred_pred = RanFor.predict(df_pred)\n",
    "df_pred_pred_proba = RanFor.predict_proba(df_pred)\n",
    "\n",
    "# Creating a new dataframe for the predictions\n",
    "df_predictions = pd.DataFrame({\n",
    "    'ID': df_pred_id,\n",
    "    'IS_GOOD': df_pred_pred,\n",
    "    'Probability_0': df_pred_pred_proba[:, 0],\n",
    "    'Probability_1': df_pred_pred_proba[:, 1]\n",
    "})\n",
    "\n",
    "df_predictions.to_excel(BASE_URL + 'credit_card_predictions.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions[df_predictions['IS_GOOD'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoost = GradientBoostingClassifier(n_estimators=200, learning_rate=0.01, max_depth=8, random_state=RANDOM_SEED)\n",
    "GradientBoost.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = GradientBoost.predict(x_train)\n",
    "y_proba_train = GradientBoost.predict_proba(x_train)\n",
    "y_pred_test = GradientBoost.predict(x_test)\n",
    "y_proba_test = GradientBoost.predict_proba(x_test)\n",
    "\n",
    "print(\"TRAIN REPORT - GradientBoostingClassifier\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"TEST REPORT - GradientBoostingClassifier\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatBst = CatBoostClassifier(verbose=50)\n",
    "\n",
    "CatBst.fit(x_train, y_train, eval_set = (x_test, y_test), early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = CatBst.predict(x_train)\n",
    "y_proba_train = CatBst.predict_proba(x_train)\n",
    "y_pred_test = CatBst.predict(x_test)\n",
    "y_proba_test = CatBst.predict_proba(x_test)\n",
    "\n",
    "print(\"TRAIN REPORT - CatBoostClassifier\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"TEST REPORT - CatBoostClassifier\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Hyperparameter tuning for a SVM classification model using Grid Search Cross-Validation\n",
    "# SVM for Probability Estimation, obtained by setting 'probability' parameter to 'True'\n",
    "param_grid = {'C': [1.0, 10.0], 'gamma': [0.01, 0.1]}\n",
    "grid_search = GridSearchCV(SVC(kernel='rbf', probability=True), param_grid, cv=3)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "svc = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "mean_test_scores = cv_results['mean_test_score']\n",
    "std_test_scores = cv_results['std_test_score']\n",
    "\n",
    "# Print the mean test scores and corresponding hyperparameters\n",
    "for mean_score, std_score, params in zip(mean_test_scores, std_test_scores, cv_results['params']):\n",
    "    print(f\"Mean Test Score: {mean_score:.4f}, Std Test Score: {std_score:.4f}, Params: {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters for the model found using 'grid_search'\n",
    "print(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an SVM model with the 'best_estimator_'\n",
    "svc_1 = SVC(kernel='rbf', probability=True, C=10.0, gamma=0.1)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "scoring_metrics = ['accuracy', 'neg_log_loss'] \n",
    "cv_results = cross_validate(svc, x_train, y_train, cv=5, scoring=scoring_metrics, return_train_score=True)\n",
    "\n",
    "train_accuracy = cv_results['train_accuracy']\n",
    "test_accuracy = cv_results['test_accuracy']\n",
    "train_log_loss = -cv_results['train_neg_log_loss']\n",
    "test_log_loss = -cv_results['test_neg_log_loss']\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Train Log Loss:\", train_log_loss)\n",
    "print(\"Test Log Loss:\", test_log_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an SVM model with more generalized estimators\n",
    "svc_2 = SVC(kernel='rbf', probability=True, C=1, gamma=0.01)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "scoring_metrics = ['accuracy', 'neg_log_loss'] \n",
    "cv_results = cross_validate(svc, x_train, y_train, cv=5, scoring=scoring_metrics, return_train_score=True)\n",
    "\n",
    "train_accuracy = cv_results['train_accuracy']\n",
    "test_accuracy = cv_results['test_accuracy']\n",
    "train_log_loss = -cv_results['train_neg_log_loss']\n",
    "test_log_loss = -cv_results['test_neg_log_loss']\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Train Log Loss:\", train_log_loss)\n",
    "print(\"Test Log Loss:\", test_log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The most notable difference is in the test log loss. The new model has considerably lower \n",
    "test log loss values compared to the previous model, which means better probability estimates.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an SVM model with more balanced estimators\n",
    "\n",
    "svc_3 = SVC(kernel='rbf', probability=True, C=1, gamma=0.1)\n",
    "\n",
    "# Perform k-fold cross-validation \n",
    "scoring_metrics = ['accuracy', 'neg_log_loss'] \n",
    "cv_results = cross_validate(svc, x_train, y_train, cv=5, scoring=scoring_metrics, return_train_score=True)\n",
    "\n",
    "train_accuracy = cv_results['train_accuracy']\n",
    "test_accuracy = cv_results['test_accuracy']\n",
    "train_log_loss = -cv_results['train_neg_log_loss']\n",
    "test_log_loss = -cv_results['test_neg_log_loss']\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Train Log Loss:\", train_log_loss)\n",
    "print(\"Test Log Loss:\", test_log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_3.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = svc_3.predict(x_train)\n",
    "y_proba_train = svc_3.predict_proba(x_train)\n",
    "y_pred_test = svc_3.predict(x_test)\n",
    "y_proba_test = svc_3.predict_proba(x_test)\n",
    "\n",
    "print(\"TRAIN REPORT - SVC\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"TEST REPORT - SVC\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corso_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
